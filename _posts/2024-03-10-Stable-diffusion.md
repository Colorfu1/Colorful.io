---
layout: post
title:  "High-Resolution Image Synthesis with Latent Diffusion Models"
date:   2024-03-10 13:45:01 +0800
categories: deep learning
tag: stable diffusion
---


* content
{:toc}
[Stable diffusion](https://platform.stability.ai/)
### Core idea
diffusion porcess from piexl space -> latent space

### Method
![Structure]()
1. we utilize an autoencoding model which learns a space that is perceptually equivalent to the image space, but offers significantly reduced computational complexity.
2. Auto ecoder: trained with a perceptual loss and a patch-based adversarial objective, downsamples the image by a factor f = H/h = W/w, and we investigate different downsampling factors f = 2m, with m âˆˆ N
4. This model can be interpreted as a VQGAN but with the quantization layer absorbed by the decoder
5. This is in contrast to previous works, which relied on an arbitrary 1D ordering of the learned space z to model its distribution autoregressively(autoregressive mothod like pixelCNN or others, they generate pixels one by one) and thereby ignored much of the inherent structure of z.
6. Cross attention mechanism.
  - Ï„Î¸ (y) âˆˆ R^(M Ã—dÏ„), like 77 * 768.(CLIPåœ¨è®­ç»ƒæ—¶è®¾å®šçš„æœ€å¤§Tokenæ•°é‡ä¸º77ï¼Œæ•…SDåœ¨å‰å‘æ¨ç†æ—¶ï¼šå¦‚è¾“å…¥çš„Promptçš„Tokenæ•°é‡è¶…è¿‡77ï¼Œåˆ™ä¼šé‡‡å–åˆ‡ç‰‡æ“ä½œï¼Œåªå–å‰77ä¸ªï¼›å¦‚è¾“å…¥Tokenæ•°é‡å°äº77ï¼Œåˆ™é‡‡å–Paddingæ“ä½œï¼Œå¾—åˆ°77x768;)
  - Here, Ï†i(zt) âˆˆ RN Ã—di  denotes a (flattened) intermediate representation of the UNet implementing. (for example UNet output 24 * 24 * 512ï¼Œit would be flattened to 576 * 512, unlike the ViT form)