---
layout: post
title:  "Scalable Diffusion Models with Transformers"
date:   2024-03-09 13:45:01 +0800
categories: deep_learning
tag: stable_diffusion
---


* content
{:toc}
[Sora's](https://openai.com/sora) base architecture
### core idea
replacing the commonly-used U-Net backbone with a transformer
DiTs with higher Gflops, lower FID, better scalability.

### Structure
![structure](https://github.com/Colorfu1/Colorful.io/blob/master/_posts/resources/2024-03-09-135235.png)
1. In this paper, we apply DiTs to latent space
2. we use off-the-shelf convolutional VAEs and transformer-based DDPMs, DiT is based on the Vision Transformer (ViT) architecture which operates on sequences of patches.![pathes](https://github.com/Colorfu1/Colorful.io/raw/master/_posts/resources/2024-03-09-135722.png)
3. The input to DiT is a spatial representation z(for 256 × 256 × 3 images, z has shape 32 × 32 × 4).
4. Three DiT block design.
    - In-context conditioning.
      - append the vector embeddings of t and c as two additional tokens in the input sequence, treating them no differently from the image tokens.(like cls token in ViT)
      - After the final block, we remove the conditioning tokens from the sequence
    - Cross-attention block.
      - We concatenate the embeddings of t and c into a length-two sequence, separate from the image token sequence
      - an additional multi-head crossattention layer following the multi-head self-attention block (embeddings of t and c as key and value)
    - Adaptive layer norm (adaLN) block
      - adaptive normalization layers [FilM](https://arxiv.org/abs/1709.07871) in GANs.
      - Rather than directly learn dimensionwise scale and shift parameters γ and β, we regress them from the sum of the embedding vectors of t and c.
    - adaLN-Zero block
      - zero-initializing the final batch norm scale factor γin each block accelerates large-scale training in the supervised learning setting [paper](https://arxiv.org/pdf/1706.02677.pdf)
      - In addition to regressing γ and β, we also regress dimensionwise scaling parameters α that are applied immediately prior to any residual connections within the DiT block

![Block compare](https://github.com/Colorfu1/Colorful.io/raw/master/_posts/resources/2024-03-09-152001.png)
5. decode our sequence of image tokens into an output noise prediction and an output diagonal covariance prediction.Both of these outputs have shape equal to the original spatial input
6. we apply the final layer norm (adaptive if using adaLN) and linearly decode each token into a p×p×2C tensor, rearrange the decoded tokens into their original spatial layout

### Experiments
![Scalability](https://github.com/Colorfu1/Colorful.io/raw/master/_posts/resources/2024-03-09-135157.png)
![Training Compute](https://github.com/Colorfu1/Colorful.io/raw/master/_posts/resources/2024-03-09-145601.png)
![Sample compute](https://github.com/Colorfu1/Colorful.io/raw/master/_posts/resources/2024-03-09-145930.png)
![FID_1](https://github.com/Colorfu1/Colorful.io/raw/master/_posts/resources/2024-03-09-145715.png)
![FID_2](https://github.com/Colorfu1/Colorful.io/raw/master/_posts/resources/2024-03-09-145725.png)
