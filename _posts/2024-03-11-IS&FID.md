---
layout: post
title:  "IS & FID"
date:   2024-03-11 15:20:01 +0800
categories: deep_learning
tag: stable_diffusion
---


* content
{:toc}
### Inception Score
#### Inception Score的基本思想
##### 基本思想：
Inception Score使用图片类别分类器来评估生成图片的质量。其中使用的图片类别分类器为Inception Net-V3。这也是Inception Score名称的由来。

Inception Net-V3 是图片分类器，在ImageNet数据集上训练。ImageNet是由120多万张图片，1000个类别组成的数据集.Inception Net-V3可以对一副图片输出一个1000分类的概率。

##### 清晰度
IS对于生成的图片x输入到Inception Net-V3中产生一个1000维的向量y。其中每一维代表数据某类的概率。对于清晰的图片来说，y的某一维应该接近1，其余维接近0。即对于类别y来说，p(y|x)的熵很小（概率比较确定）。

##### 多样性
对于所有的生成图片，应该均匀分布在所有的类别中。比如共生成10000张图片，对于1000类别，每一类应该生成10张图片。即 
$p(y) = \sum p(y|x^{(i)})$的熵很大，总体分布接近均匀分布。

#### Inception Score的公式
直观感受，IS是对生成图片清晰度和多样性的衡量，IS值越大越好。具体公式如下
$$
IS(G) = \exp(\mathbb{E}_{\boldsymbol{x} \sim p_g} D_{KL}(p(y|\boldsymbol{x}) | p(y)))
$$

其中

$\mathbb{E}$：遍历所有的生成样本，求平均值

$D_{KL}$：KL散度，用于衡量分布$p(y|\boldsymbol{x})$和p(y)之间的近似程度

$p(y|\boldsymbol{x})$：对于图片x，属于所有类别的概率分布。对于给定图片x，表示为一个1000维数向量。

$p(y)$：边缘概率，具体实现为对于所有的验证图片x，计算得到p(y|x)，再求所有向量平均值。

我们希望生成的图片，足够清晰且生成类别多样，所有IS越大越好。并且对于Inception Net-V3由于是1000分类任务，所以IS(G)有最大值
$IS(G) \leq 1000$

#### Inception Score的问题
数据集问题
Inception Score是基于Inception Net-V3得出的，而Inception Net-V3是在ImageNet上1000分类任务。所以生成模型应该也是在ImageNet上训练，生成ImageNet相似图片。不能生成任意的图片，而直接套用Inception Net-V3。
比如说，使用Inception Net-V3来计算p(y|x)的熵，在ImageNet上计算结果为1.97bit。在CIFAR-10上计算结果是4.664bit，在随机噪声图片上计算结果是6.512bit。

可以看出真实的图片数据集CIFAR-10居然和随机噪声图片的结果相近这是不科学的。

总结：不能使用在一个数据集上训练分类模型，评估在另一个数据集上训练的生成模型

#### Inception Score敏感性问题

使用pytorch、tensorflow、keras等不同框架下的Inception Net权值，在同样的分类精度下，计算同一个数据集的IS。IS的差别很大，仅仅由于使用的框架不同，IS分值可以相差11.5%。

总结：神经网络中权值的细节改变可能很大的影响IS分数

#### Inception Score高的图片不一定真实

由于Inception Score是根据分类器进行给分，我们可以根据分类器的结果来进行刷分。刷分的关键是全体图片的类别要多样，其中具体一副图片，分类器计算出的熵要比较低。

比如我现有数据集50000张，取第1张图片，使用Inception Net-V3计算分类概率，要使图片第1类概率达到最大。使用梯度下降，对图片进行更新，直到第一类概率极大。如此对第2图片强行调整至符合第2类......遍历所有的图片之后，在1000类中，每一类有10张图片，且每张图片的分类概率都很明确。但这样生成的图片大概率是不真实的

#### Inception Score低的图片不一定差

如果我给出一张真实的图片，但并不属于Inception Net-V3的1000分类中的任何一类。分类器无法判别，那么Inception Score分数不高，但图像是真实的。

#### Inception Score的多样性检验有局限性

Inception Score检测生成图片是否多样，是根据生成的类别进行检验判断。如果我的模型输出图片，类别是平均分配的。但每一类中，图片都一样，也就是mode collapse。这种情况Inception Score是无法检测的

#### Inception Score不能反映过拟合

如果我的神经网络只是单纯的拷贝训练集的图片，那么Inception Score肯定是很高的，但这样的生成模型是没有意义的。

总结：Inception Score得分过于依赖分类器，是一种间接的对图片质量评估的方法，没有考虑真实数据与生成数据的具体差异。Inception Score是基于ImageNet得到的，在IS看来，凡是不像ImageNet的数据，都是不真实的。

### Fréchet Inception Distance
#### Fréchet Inception Distance的基本思想
基本思想：直接考虑生成数据和真实数据在feature层次的距离，不再额外的借助分类器。因此来衡量生成图片和真实图片的距离。

众所周知，预训练好的神经网络在高层可以提取图片的抽象特征。FID使用Inception Net-V3全连接前的2048维向量作为图片的feature。

#### Fréchet Inception Distance的公式
直观感受，FID是反应生成图片和真实图片的距离，数据越小越好。专业来说，FID是衡量两个多元正态分布的距离，其公式如下
$$
FID = ||\mu_r - \mu_g||^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r\Sigma_g)^{1/2})
$$

其中\
$\mu_r$：真实图片的特征均值 \
$\mu_g$：生成图片的特征均值 \
$\Sigma_r$：真实图片的协方差矩阵 \
$\Sigma_g$：生成图片的协方差矩阵 \
$\text{Tr}$：迹
#### Fréchet Inception Distance的优缺点
##### Fréchet Inception Distance优点
生成模型的训练集可以和Inception Net-V3不同
刷分不会导致生成图片质量变差
##### Fréchet Inception Distance的缺点
FID是衡量多元正态分布直接按的距离，但提取的图片特征不一定是符合多元正态分布的
无法解决过拟合问题，如果生成模型只能生成和训练集一模一样的数据无法检测